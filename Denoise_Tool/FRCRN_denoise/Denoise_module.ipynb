{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b6bfd5-6965-4d54-9300-692f7c45bdee",
   "metadata": {},
   "source": [
    "### Import necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2f3f42-78af-4aeb-8f12-e4cd7f45ba81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "2.3.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\Denoise-module-main\\Denoise-module-main\\Denoise_Tool\\FRCRN_denoise\\noise_addition_utils.py:15: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "#This script is used to import all the necessary libraries for the project\n",
    "#The output of this script is the version of the libraries imported\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "#import tarfile\n",
    "import multiprocessing\n",
    "\n",
    "import scipy\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from pathlib import Path\n",
    "\n",
    "from metrics import AudioMetrics\n",
    "from metrics import AudioMetrics2\n",
    "#from Audio_metrics import AudioMetrics2\n",
    "import noise_addition_utils\n",
    "from pypesq import pesq\n",
    "import shutil\n",
    "\n",
    "#import pathlib\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30e4c0c-8271-46c7-9e0c-78ad266f4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Helper functions.\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def denoise_audio(input_path, output_path, smoothing_factor):\n",
    "    # Load the audio file\n",
    "    snd = parselmouth.Sound(input_path)\n",
    "\n",
    "    # Apply smoothing to reduce noise\n",
    "    snd_denoised = snd.copy()\n",
    "    #snd_denoised = call(snd_denoised, \"Smooth\", smoothing_factor)\n",
    "    snd_denoised = call(snd_denoised, \"Reduce noise\", 0.0, 0.0, 0.025, 80.0, 10000.0, 40.0,-20, \"Spectral-subtraction\")\n",
    "    # Save the denoised audio\n",
    "    snd_denoised.save(output_path, \"WAV\")\n",
    "def get_stats(waveform, sample_rate=None, src=None):\n",
    "    max_ = waveform.max().numpy()\n",
    "    min_ = waveform.min().numpy()\n",
    "    mean_ = waveform.mean().numpy()\n",
    "    std_ = waveform.std().numpy()\n",
    "    return max_,min_,mean_,std_\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "    if src:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Source:\", src)\n",
    "        print(\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(\"Sample Rate:\", sample_rate)\n",
    "        print(\"Shape:\", tuple(waveform.shape))\n",
    "        print(\"Dtype:\", waveform.dtype)\n",
    "        print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "        print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "        print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "        print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "        print()\n",
    "        print(waveform)\n",
    "        print()\n",
    "    # max_ = waveform.max().numpy()\n",
    "    # min_ = waveform.min().numpy()\n",
    "    # mean_ = waveform.mean().numpy()\n",
    "    # std_ = waveform.std().numpy()\n",
    "    # return max_,min_,mean_,std_\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "    axes[c].grid(True)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "    if ylim:\n",
    "      axes[c].set_ylim(ylim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "  waveform = waveform.numpy()\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def get_spectrogram(\n",
    "    n_fft = 400,\n",
    "    win_len = None,\n",
    "    hop_len = None,\n",
    "    power = 2.0,\n",
    "):\n",
    "  waveform, _ = get_speech_sample()\n",
    "  spectrogram = T.Spectrogram(\n",
    "      n_fft=n_fft,\n",
    "      win_length=win_len,\n",
    "      hop_length=hop_len,\n",
    "      center=True,\n",
    "      pad_mode=\"reflect\",\n",
    "      power=power,\n",
    "  )\n",
    "  return spectrogram(waveform)\n",
    "def resample_wav_files(input_path, output_path, target_sr):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Get a list of all WAV files in the input directory and its subfolders\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.wav'):\n",
    "                # Read the input WAV file\n",
    "                input_file = os.path.join(root, file_name)\n",
    "                audio, sr = librosa.load(input_file, sr=target_sr)\n",
    "\n",
    "                # Write the resampled audio to the output WAV file\n",
    "                output_dir = os.path.join(output_path, os.path.relpath(root, input_path))\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                output_file = os.path.join(output_dir, file_name)\n",
    "                sf.write(output_file, audio, target_sr)\n",
    "def copy_wav_files_to_single_directory(input_path, output_path):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Get a list of all WAV files in the input directory and its subfolders\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.wav'):\n",
    "                # Copy the WAV file to the output directory with the original filename\n",
    "                input_file = os.path.join(root, file_name)\n",
    "                output_file = os.path.join(output_path, file_name)\n",
    "                shutil.copy2(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff8aa7-a05d-4d2c-9f26-e23070505318",
   "metadata": {},
   "source": [
    "### Spectral Subtraction method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908405dd-421d-41b5-8c50-2893fb299d81",
   "metadata": {},
   "source": [
    "#### Define the path to denoise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c40240e-bf2c-496f-94fc-460d8b9087b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/nghna/Downloads/drive-download-20241022T091430Z-001/1.1.wav')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahna_dataset = sorted(list(Path(r\"C:\\Users\\nghna\\Downloads\\drive-download-20241022T091430Z-001\").rglob('*.wav')))\n",
    "bahna_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d6755c0-a67e-4637-9416-8e68184977ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Max, Min, Mean, Std, Noise_level_before_denoised, Max_after_denoised, Min_after_denoised, Mean_after_denoised, Std_after_denoised, Noise_level_after_denoised]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe to record statistics\n",
    "stat_bahna_spectral_subtraction = pd.DataFrame(columns=['Name','Max', 'Min', 'Mean','Std','Noise_level_before_denoised','Max_after_denoised', 'Min_after_denoised', 'Mean_after_denoised','Std_after_denoised','Noise_level_after_denoised'])\n",
    "stat_bahna_spectral_subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c68dd6d-f6f7-43c7-a748-9e6d1215d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nghna\\Downloads\\drive-download-20241022T091430Z-001\\1.1.wav\n",
      "C:\\Users\\nghna\\Downloads\\drive-download-20241022T091430Z-001\\1.1_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nghna\\AppData\\Local\\Temp\\ipykernel_28736\\3705012350.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  stat_bahna_spectral_subtraction=pd.concat([stat_bahna_spectral_subtraction,df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nghna\\Downloads\\drive-download-20241022T091430Z-001\\1.2.wav\n",
      "C:\\Users\\nghna\\Downloads\\drive-download-20241022T091430Z-001\\1.2_denoised_spectral_subtraction.wav\n"
     ]
    }
   ],
   "source": [
    "#Load file to denoise\n",
    "for i in bahna_dataset:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    max_,min_,mean_,std_ = get_stats(waveform, sample_rate = sample_rate)\n",
    "    # Calculate noise level\n",
    "    if std_!=0 :\n",
    "        noise_level = 20*( np.log10(std_/max_))\n",
    "    else:\n",
    "        noise_level = 0\n",
    "    normalized_path = os.path.normpath(i)\n",
    "    input_path = os.path.splitext(normalized_path)[0] + os.path.splitext(normalized_path)[1]\n",
    "    denoised_path = os.path.splitext(normalized_path)[0] + \"_denoised_spectral_subtraction\" + os.path.splitext(normalized_path)[1]\n",
    "    snd = parselmouth.Sound(input_path)\n",
    "    snd_denoised = snd.copy()\n",
    "    snd_denoised = call(snd_denoised, \"Reduce noise\", 0.0, 0.0, 0.025, 80.0, 10000.0, 40.0,noise_level, \"Spectral-subtraction\")\n",
    "    # Save the denoised audio\n",
    "    snd_denoised.save(denoised_path, \"WAV\")\n",
    "    print(denoised_path)\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    max_after,min_after,mean_after,std_after=get_stats(waveform_denoised, sample_rate=sample_rate_denoised)\n",
    "    if std_after!=0 :\n",
    "        noise_level_after = 10*( np.log10(std_after/max_after))\n",
    "    else:\n",
    "        noise_level_after = 0\n",
    "    df = pd.DataFrame({\"Name\":[i],\"Max\":[max_],\"Min\":[min_],\"Mean\":[mean_],\"Std\":[std_],\"Noise_level_before_denoised\":[noise_level],'Max_after_denoised':[max_after], 'Min_after_denoised':[min_after], 'Mean_after_denoised':[mean_after],'Std_after_denoised':[std_after],'Noise_level_after_denoised':[noise_level_after]})\n",
    "    stat_bahna_spectral_subtraction=pd.concat([stat_bahna_spectral_subtraction,df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b6c8f2-cbd5-4b99-8ce1-a4f222301f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Projects\\Denoise-module-main\\Denoise-module...</td>\n",
       "      <td>0.6552124</td>\n",
       "      <td>-0.7651062</td>\n",
       "      <td>-3.0624975e-05</td>\n",
       "      <td>0.07685376</td>\n",
       "      <td>-18.614340</td>\n",
       "      <td>0.65423584</td>\n",
       "      <td>-0.76345825</td>\n",
       "      <td>-2.699632e-08</td>\n",
       "      <td>0.07657743</td>\n",
       "      <td>-9.316335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Projects\\Denoise-module-main\\Denoise-module...</td>\n",
       "      <td>0.55578613</td>\n",
       "      <td>-0.4998474</td>\n",
       "      <td>-3.9136925e-05</td>\n",
       "      <td>0.0951897</td>\n",
       "      <td>-15.326356</td>\n",
       "      <td>0.5375061</td>\n",
       "      <td>-0.47183228</td>\n",
       "      <td>1.0024613e-06</td>\n",
       "      <td>0.090305954</td>\n",
       "      <td>-7.746670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Projects\\Denoise-module-main\\Denoise-module...</td>\n",
       "      <td>0.47247314</td>\n",
       "      <td>-0.53967285</td>\n",
       "      <td>-2.9462188e-05</td>\n",
       "      <td>0.048951853</td>\n",
       "      <td>-19.692160</td>\n",
       "      <td>0.44641113</td>\n",
       "      <td>-0.47470093</td>\n",
       "      <td>1.3798474e-05</td>\n",
       "      <td>0.03827656</td>\n",
       "      <td>-10.668021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Projects\\Denoise-module-main\\Denoise-module...</td>\n",
       "      <td>0.4461975</td>\n",
       "      <td>-0.56170654</td>\n",
       "      <td>-4.4831922e-05</td>\n",
       "      <td>0.059409264</td>\n",
       "      <td>-17.513460</td>\n",
       "      <td>0.44207764</td>\n",
       "      <td>-0.55718994</td>\n",
       "      <td>-3.0327021e-06</td>\n",
       "      <td>0.05851719</td>\n",
       "      <td>-8.782151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Projects\\Denoise-module-main\\Denoise-module...</td>\n",
       "      <td>0.32443237</td>\n",
       "      <td>-0.37664795</td>\n",
       "      <td>-1.7288974e-05</td>\n",
       "      <td>0.046413366</td>\n",
       "      <td>-16.889622</td>\n",
       "      <td>0.32235718</td>\n",
       "      <td>-0.3694458</td>\n",
       "      <td>1.4427932e-06</td>\n",
       "      <td>0.044849005</td>\n",
       "      <td>-8.565845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name         Max          Min  \\\n",
       "0  C:\\Projects\\Denoise-module-main\\Denoise-module...   0.6552124   -0.7651062   \n",
       "1  C:\\Projects\\Denoise-module-main\\Denoise-module...  0.55578613   -0.4998474   \n",
       "2  C:\\Projects\\Denoise-module-main\\Denoise-module...  0.47247314  -0.53967285   \n",
       "3  C:\\Projects\\Denoise-module-main\\Denoise-module...   0.4461975  -0.56170654   \n",
       "4  C:\\Projects\\Denoise-module-main\\Denoise-module...  0.32443237  -0.37664795   \n",
       "\n",
       "             Mean          Std  Noise_level_before_denoised  \\\n",
       "0  -3.0624975e-05   0.07685376                   -18.614340   \n",
       "1  -3.9136925e-05    0.0951897                   -15.326356   \n",
       "2  -2.9462188e-05  0.048951853                   -19.692160   \n",
       "3  -4.4831922e-05  0.059409264                   -17.513460   \n",
       "4  -1.7288974e-05  0.046413366                   -16.889622   \n",
       "\n",
       "  Max_after_denoised Min_after_denoised Mean_after_denoised  \\\n",
       "0         0.65423584        -0.76345825       -2.699632e-08   \n",
       "1          0.5375061        -0.47183228       1.0024613e-06   \n",
       "2         0.44641113        -0.47470093       1.3798474e-05   \n",
       "3         0.44207764        -0.55718994      -3.0327021e-06   \n",
       "4         0.32235718         -0.3694458       1.4427932e-06   \n",
       "\n",
       "  Std_after_denoised  Noise_level_after_denoised  \n",
       "0         0.07657743                   -9.316335  \n",
       "1        0.090305954                   -7.746670  \n",
       "2         0.03827656                  -10.668021  \n",
       "3         0.05851719                   -8.782151  \n",
       "4        0.044849005                   -8.565845  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_spectral_subtraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fa17d7f-85db-4241-8675-fbf73ad47d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31530017-c342-41da-ad7c-e573c18e8161",
   "metadata": {},
   "source": [
    "### FRCRN method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d55f98-2e3e-40f0-b5ec-3fda6a5195eb",
   "metadata": {},
   "source": [
    "This model use a fixed input with Sampling frequency is 16khz so we have to resample the input before we put it into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e299eb1a-f3f0-4b81-b12c-f6a92babf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage resample to 16khz\n",
    "input_directory = r'C:\\Projects\\Denoise-module-main\\Denoise-module-main\\Test'\n",
    "output_directory = r'C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget'\n",
    "target_sampling_rate = 16000\n",
    "\n",
    "resample_wav_files(input_directory, output_directory, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c509e1-e2d3-448f-8907-03183afb765c",
   "metadata": {},
   "source": [
    "#### Define path to denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7611030e-57df-4ad3-ad48-b5715c1b1545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Projects/Denoise-module-main/Denoise-module-main/testTarget/0001.2.wav')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahna_dataset_FRCRN = sorted(list(Path(r\"C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\").rglob('*.wav')))\n",
    "bahna_dataset_FRCRN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb972edd-b18b-4bb7-a006-486a05456afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Max, Min, Mean, Std, Noise_level_before_denoised, Max_after_denoised, Min_after_denoised, Mean_after_denoised, Std_after_denoised, Noise_level_after_denoised]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_FRCRN = pd.DataFrame(columns=['Name','Max', 'Min', 'Mean','Std','Noise_level_before_denoised','Max_after_denoised', 'Min_after_denoised', 'Mean_after_denoised','Std_after_denoised','Noise_level_after_denoised'])\n",
    "stat_bahna_FRCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20dd07c3-1261-4f81-884c-18d75e40eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:26:42,955 - modelscope - INFO - PyTorch version 2.3.1 Found.\n",
      "2024-06-25 15:26:42,957 - modelscope - INFO - Loading ast index from C:\\Users\\nghna\\.cache\\modelscope\\ast_indexer\n",
      "2024-06-25 15:26:43,247 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 c60ca7d7f8b85e22d9ef728cbad5174f and a total number of 980 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer is not installed, please install it if you want to use related modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12619a12-fb5b-47a2-b46d-935eb6204478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:26:44,861 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:26:44,862 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:26:44,864 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:26:45,175 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:26:45,176 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:26:45,176 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:26:45,176 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:26:45,179 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 55913)\n",
      "padding: 19913\n",
      "inputs after padding:(1, 75826)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nghna\\AppData\\Local\\Temp\\ipykernel_4772\\3691686857.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  stat_bahna_FRCRN=pd.concat([stat_bahna_FRCRN,df_FRCRN], ignore_index=True)\n",
      "2024-06-25 15:27:03,716 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:27:03,717 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:27:03,718 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.2_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.2_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:03,986 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:27:03,988 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:27:03,988 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:27:03,989 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:27:03,992 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 55913)\n",
      "padding: 19913\n",
      "inputs after padding:(1, 75826)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:07,015 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:27:07,016 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:27:07,018 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.2_denoised_spectral_subtraction_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:07,381 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:27:07,381 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:27:07,382 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:27:07,382 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:27:07,384 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 27509)\n",
      "padding: 491\n",
      "inputs after padding:(1, 28000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:15,894 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:27:15,895 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:27:15,898 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.3_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.3_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:16,152 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:27:16,152 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:27:16,153 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:27:16,153 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:27:16,155 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 27509)\n",
      "padding: 491\n",
      "inputs after padding:(1, 28000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:17,165 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:27:17,165 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:27:17,168 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.3_denoised_spectral_subtraction_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:27:17,431 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:27:17,431 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:27:17,432 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:27:17,432 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:27:17,434 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 42707)\n",
      "padding: 18707\n",
      "inputs after padding:(1, 61414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:10,767 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:28:10,769 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:28:10,772 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.4_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.4_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:11,044 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:28:11,045 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:28:11,045 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:28:11,045 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:28:11,048 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 42707)\n",
      "padding: 18707\n",
      "inputs after padding:(1, 61414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:13,612 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:28:13,613 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:28:13,615 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.4_denoised_spectral_subtraction_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:13,885 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:28:13,886 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:28:13,886 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:28:13,886 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:28:13,890 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 31086)\n",
      "padding: 19086\n",
      "inputs after padding:(1, 50172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:17,978 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:28:17,980 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:28:17,982 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.5_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.5_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:18,276 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:28:18,276 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:28:18,276 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:28:18,276 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:28:18,280 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 31086)\n",
      "padding: 19086\n",
      "inputs after padding:(1, 50172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:20,179 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:28:20,180 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:28:20,182 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\0001.5_denoised_spectral_subtraction_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\noisy.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:28:20,459 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:28:20,460 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:28:20,460 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:28:20,460 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:28:20,463 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 54784)\n",
      "padding: 18784\n",
      "inputs after padding:(1, 73568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:29,951 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:29:29,952 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:29:29,954 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\noisy_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\noisy_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:30,238 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:29:30,238 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:29:30,238 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:29:30,238 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:29:30,241 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 54784)\n",
      "padding: 18784\n",
      "inputs after padding:(1, 73568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:33,279 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:29:33,280 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:29:33,283 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\noisy_denoised_spectral_subtraction_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\Test0001.1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:33,668 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:29:33,668 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:29:33,669 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:29:33,669 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:29:33,671 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 104000)\n",
      "padding: 20000\n",
      "inputs after padding:(1, 124000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:51,888 - modelscope - INFO - initiate model from ./demo_model\n",
      "2024-06-25 15:29:51,889 - modelscope - INFO - initiate model from location ./demo_model.\n",
      "2024-06-25 15:29:51,891 - modelscope - INFO - initialize model from ./demo_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\Test0001.1_denoised_FRCRN.wav\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\Test0001.1_denoised_spectral_subtraction.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:29:52,172 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-25 15:29:52,173 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-25 15:29:52,173 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': './demo_model'}. trying to build by task and model information.\n",
      "2024-06-25 15:29:52,173 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-25 15:29:52,176 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 104000)\n",
      "padding: 20000\n",
      "inputs after padding:(1, 124000)\n",
      "C:\\Projects\\Denoise-module-main\\Denoise-module-main\\testTarget\\Test0001.1_denoised_spectral_subtraction_denoised_FRCRN.wav\n"
     ]
    }
   ],
   "source": [
    "for i in bahna_dataset_FRCRN:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    max_,min_,mean_,std_ = get_stats(waveform, sample_rate = sample_rate)\n",
    "    if std_!=0 :\n",
    "        noise_level = 10*( np.log10(std_/max_))\n",
    "    else:\n",
    "        noise_level = 0\n",
    "    # df = pd.DataFrame({\"Name\":[i],\"Std\":[std_],\"Noise_level\":[noise_level]})\n",
    "    # stat_bahna=pd.concat([stat_bahna,df], ignore_index=True)\n",
    "    normalized_path = os.path.normpath(i)\n",
    "    input_path = os.path.splitext(normalized_path)[0] + os.path.splitext(normalized_path)[1]\n",
    "    denoised_path = os.path.splitext(normalized_path)[0] + \"_denoised_FRCRN\" + os.path.splitext(normalized_path)[1]\n",
    "    \n",
    "    # denoised audio    \n",
    "    ans = pipeline(\n",
    "        Tasks.acoustic_noise_suppression,\n",
    "        model='./demo_model')\n",
    "    result = ans(\n",
    "        str(i),\n",
    "        output_path=denoised_path)\n",
    "    print(denoised_path)\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    max_after,min_after,mean_after,std_after=get_stats(waveform_denoised, sample_rate=sample_rate_denoised)\n",
    "    if std_after!=0 :\n",
    "        noise_level_after = 10*( np.log10(std_after/max_after))\n",
    "    else:\n",
    "        noise_level_after = 0\n",
    "    df_FRCRN = pd.DataFrame({\"Name\":[i],\"Max\":[max_],\"Min\":[min_],\"Mean\":[mean_],\"Std\":[std_],\"Noise_level_before_denoised\":[noise_level],'Max_after_denoised':[max_after], 'Min_after_denoised':[min_after], 'Mean_after_denoised':[mean_after],'Std_after_denoised':[std_after],'Noise_level_after_denoised':[noise_level_after]})\n",
    "    stat_bahna_FRCRN=pd.concat([stat_bahna_FRCRN,df_FRCRN], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9065f53-150e-40d9-ba58-0de8bd28ceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Max, Min, Mean, Std, Noise_level_before_denoised, Max_after_denoised, Min_after_denoised, Mean_after_denoised, Std_after_denoised, Noise_level_after_denoised]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_FRCRN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2c3bc-5815-4c1c-85b6-3f679844afdd",
   "metadata": {},
   "source": [
    "### Evaluation (PESQ, STOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa62a9-70be-446c-a14a-47f1bb4f4d50",
   "metadata": {},
   "source": [
    "PESQ Score only support for sampling rate Fs = 8khz (defined as narrow band) or 16khz (defined as wide band) only so we have to resample it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0db3dc4-68c8-48c2-bf7e-9073022d9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage resample to 16khz\n",
    "input_directory = r'D:/Master/Thesis/FRCRN/Summary/Test/'\n",
    "output_directory = 'D:/Master/Thesis/FRCRN/Summary/Test resample'\n",
    "target_sampling_rate = 16000\n",
    "\n",
    "resample_wav_files(input_directory, output_directory, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e974d8d4-e268-4c9a-b3a7-119ce108b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage Datasets/clean_testset_wav\n",
    "input_directory = 'D:\\Master\\Thesis\\FRCRN\\CTV bana to add noise\\Bnh nh'\n",
    "output_file = 'D:\\Master\\Thesis\\FRCRN\\CTV bana to add noise\\Bnh nh only'\n",
    "\n",
    "copy_wav_files_to_single_directory(input_directory, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad086a35-43b3-4659-9c97-f9fea33e1a82",
   "metadata": {},
   "source": [
    "#### Example evaluate PESQ (wide band - 16khz) and STOI for 1 clean - denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cb578b8-3eaa-49b2-a244-43f39f5233a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'C:\\\\Projects\\\\Denoise-module-main\\\\Denoise-module-main\\\\Test0001.1.wav': System error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDenoise-module-main\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDenoise-module-main\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTest0001.1.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDenoise-module-main\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDenoise-module-main\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTest0001.1_denoised_spectral_subtraction.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m waveform_denoised, sample_rate_denoised \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(n)\n",
      "File \u001b[1;32mc:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[0;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    141\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msoundfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[0;32m    223\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nghna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'C:\\\\Projects\\\\Denoise-module-main\\\\Denoise-module-main\\\\Test0001.1.wav': System error."
     ]
    }
   ],
   "source": [
    "m = 'C:\\\\Projects\\\\Denoise-module-main\\\\Denoise-module-main\\\\Test0001.1.wav'\n",
    "n = 'C:\\\\Projects\\\\Denoise-module-main\\\\Denoise-module-main\\\\Test0001.1_denoised_spectral_subtraction.wav'\n",
    "waveform, sample_rate = torchaudio.load(m)\n",
    "waveform_denoised, sample_rate_denoised = torchaudio.load(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0a122-193e-48d5-b783-528898772816",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e473ee0f-f080-47b0-9a0c-fb214ff40081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.433448314666748"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.audio import PerceptualEvaluationSpeechQuality\n",
    "# pesq = PerceptualEvaluationSpeechQuality(8000, 'nb')\n",
    "# pesq(preds, target)\n",
    "\n",
    "wb_pesq = PerceptualEvaluationSpeechQuality(sample_rate, 'wb')\n",
    "wb_pesq(waveform_denoised,waveform).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ff2de43-9b00-4e7a-bd28-26401054f2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990944266319275"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.audio.stoi import ShortTimeObjectiveIntelligibility\n",
    "stoi = ShortTimeObjectiveIntelligibility(sample_rate, False)\n",
    "stoi(waveform_denoised,waveform).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5feefd-b6a3-44b9-8936-da07c2686831",
   "metadata": {},
   "source": [
    "#### To evaluate multiple sample at one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5aebea0-5c89-4d14-a5ae-1f9f79e3665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['PESQ','STOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83dda1d-272a-4413-af06-da1204625b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bahna_dataset_FRCRN:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    #normalized_path = os.path.normpath(i)\n",
    "    denoised_path = os.path.splitext(i)[0] + \"_denoised_FRCRN\" + os.path.splitext(i)[1]\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    print(denoised_path)\n",
    "    wb_pesq = PerceptualEvaluationSpeechQuality(sample_rate, 'wb')\n",
    "    stoi = ShortTimeObjectiveIntelligibility(sample_rate, False)\n",
    "    metric = pd.DataFrame({\"PESQ\":[wb_pesq(waveform, waveform_denoised)],\"STOI\":[stoi(waveform, waveform_denoised)]})\n",
    "    metrics = pd.concat([metrics,metric], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e8f2526-b10c-4f69-89ce-5716af851226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESQ</th>\n",
       "      <th>STOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(4.1133)</td>\n",
       "      <td>tensor(0.9992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.9175)</td>\n",
       "      <td>tensor(0.9248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(2.6582)</td>\n",
       "      <td>tensor(0.9736)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(2.6802)</td>\n",
       "      <td>tensor(0.9624)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(4.3995)</td>\n",
       "      <td>tensor(0.9952)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PESQ            STOI\n",
       "0  tensor(4.1133)  tensor(0.9992)\n",
       "1  tensor(1.9175)  tensor(0.9248)\n",
       "2  tensor(2.6582)  tensor(0.9736)\n",
       "3  tensor(2.6802)  tensor(0.9624)\n",
       "4  tensor(4.3995)  tensor(0.9952)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
